{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx = pd.read_csv(\"../data/transformed_data.csv\",index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>changeClose</th>\n",
       "      <th>changeHC</th>\n",
       "      <th>changeLC</th>\n",
       "      <th>nextchange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-30</th>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.001568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07</th>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>-0.022750</td>\n",
       "      <td>0.007250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14</th>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>-0.006320</td>\n",
       "      <td>0.016407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21</th>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.017781</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.005819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28</th>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.002856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            changeClose  changeHC  changeLC  nextchange\n",
       "Date                                                   \n",
       "2019-11-30     0.009819  0.014038  0.002296    0.001568\n",
       "2019-12-07     0.001568  0.003058 -0.022750    0.007250\n",
       "2019-12-14     0.007250  0.011620 -0.006320    0.016407\n",
       "2019-12-21     0.016407  0.017781  0.004669    0.005819\n",
       "2019-12-28     0.005819  0.008258 -0.000220   -0.002856"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spx.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = spx.iloc[:,:-1]\n",
    "ydata = spx.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 3)\n",
      "(2608,)\n"
     ]
    }
   ],
   "source": [
    "print(xdata.shape)\n",
    "print(ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(spx)*.8)\n",
    "test_size = len(spx)-train_size\n",
    "\n",
    "#change y's if multiple outputs\n",
    "xtrain,xtest = xdata.iloc[0:train_size,:], xdata.iloc[train_size:len(spx),:]\n",
    "ytrain,ytest = ydata.iloc[0:train_size], ydata.iloc[train_size:len(spx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2086 522\n",
      "2086 522\n"
     ]
    }
   ],
   "source": [
    "print(len(xtrain),len(xtest))\n",
    "print(len(ytrain),len(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX = StandardScaler()\n",
    "scalerY = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sc = scalerX.fit_transform(xtrain.to_numpy())\n",
    "xtest_sc = scalerX.transform(xtest.to_numpy())\n",
    "ytrain_sc = scalerY.fit_transform(ytrain.to_numpy().reshape(-1,1))\n",
    "ytest_sc = scalerY.transform(ytest.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_data_transform(x_data, y_data, num_steps=5):\n",
    "    \"\"\" Changes data to the format for LSTM training \n",
    "    for sliding window approach \"\"\"\n",
    "    # Prepare the list for the transformed data\n",
    "    X, y = list(), list()\n",
    "    # Loop of the entire data set\n",
    "    for i in range(x_data.shape[0]):\n",
    "        # compute a new (sliding window) index\n",
    "        end_ix = i + num_steps\n",
    "        # if index is larger than the size of the dataset, we stop\n",
    "        if end_ix >= x_data.shape[0]:\n",
    "            break\n",
    "        # Get a sequence of data for x\n",
    "        seq_X = x_data[i:end_ix]\n",
    "        # Get only the last element of the sequency for y\n",
    "        seq_y = y_data[end_ix]\n",
    "        # Append the list with sequencies\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "    # Make final arrays\n",
    "    x_array = np.array(X)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "\n",
    "xtrain_transformed, ytrain_transformed = lstm_data_transform(xtrain_sc, ytrain_sc, num_steps=num_steps)\n",
    "xtest_transformed, ytest_transformed = lstm_data_transform(xtest_sc, ytest_sc, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(num_steps, 3),return_sequences=False))\n",
    "# model.add(Dense(3,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 4)                 128       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "130/130 - 1s - loss: 0.7316\n",
      "Epoch 2/100\n",
      "130/130 - 1s - loss: 0.7304\n",
      "Epoch 3/100\n",
      "130/130 - 1s - loss: 0.7284\n",
      "Epoch 4/100\n",
      "130/130 - 1s - loss: 0.7275\n",
      "Epoch 5/100\n",
      "130/130 - 1s - loss: 0.7270\n",
      "Epoch 6/100\n",
      "130/130 - 1s - loss: 0.7274\n",
      "Epoch 7/100\n",
      "130/130 - 1s - loss: 0.7254\n",
      "Epoch 8/100\n",
      "130/130 - 1s - loss: 0.7264\n",
      "Epoch 9/100\n",
      "130/130 - 1s - loss: 0.7256\n",
      "Epoch 10/100\n",
      "130/130 - 1s - loss: 0.7248\n",
      "Epoch 11/100\n",
      "130/130 - 1s - loss: 0.7242\n",
      "Epoch 12/100\n",
      "130/130 - 1s - loss: 0.7229\n",
      "Epoch 13/100\n",
      "130/130 - 1s - loss: 0.7211\n",
      "Epoch 14/100\n",
      "130/130 - 1s - loss: 0.7205\n",
      "Epoch 15/100\n",
      "130/130 - 1s - loss: 0.7183\n",
      "Epoch 16/100\n",
      "130/130 - 1s - loss: 0.7181\n",
      "Epoch 17/100\n",
      "130/130 - 1s - loss: 0.7160\n",
      "Epoch 18/100\n",
      "130/130 - 1s - loss: 0.7159\n",
      "Epoch 19/100\n",
      "130/130 - 1s - loss: 0.7136\n",
      "Epoch 20/100\n",
      "130/130 - 1s - loss: 0.7106\n",
      "Epoch 21/100\n",
      "130/130 - 1s - loss: 0.7083\n",
      "Epoch 22/100\n",
      "130/130 - 1s - loss: 0.7098\n",
      "Epoch 23/100\n",
      "130/130 - 1s - loss: 0.7061\n",
      "Epoch 24/100\n",
      "130/130 - 1s - loss: 0.7042\n",
      "Epoch 25/100\n",
      "130/130 - 1s - loss: 0.7029\n",
      "Epoch 26/100\n",
      "130/130 - 1s - loss: 0.7013\n",
      "Epoch 27/100\n",
      "130/130 - 1s - loss: 0.6995\n",
      "Epoch 28/100\n",
      "130/130 - 1s - loss: 0.6995\n",
      "Epoch 29/100\n",
      "130/130 - 1s - loss: 0.6953\n",
      "Epoch 30/100\n",
      "130/130 - 1s - loss: 0.6961\n",
      "Epoch 31/100\n",
      "130/130 - 1s - loss: 0.6915\n",
      "Epoch 32/100\n",
      "130/130 - 1s - loss: 0.6898\n",
      "Epoch 33/100\n",
      "130/130 - 1s - loss: 0.6881\n",
      "Epoch 34/100\n",
      "130/130 - 1s - loss: 0.6872\n",
      "Epoch 35/100\n",
      "130/130 - 1s - loss: 0.6843\n",
      "Epoch 36/100\n",
      "130/130 - 1s - loss: 0.6836\n",
      "Epoch 37/100\n",
      "130/130 - 1s - loss: 0.6766\n",
      "Epoch 38/100\n",
      "130/130 - 1s - loss: 0.6784\n",
      "Epoch 39/100\n",
      "130/130 - 1s - loss: 0.6722\n",
      "Epoch 40/100\n",
      "130/130 - 1s - loss: 0.6714\n",
      "Epoch 41/100\n",
      "130/130 - 1s - loss: 0.6696\n",
      "Epoch 42/100\n",
      "130/130 - 1s - loss: 0.6639\n",
      "Epoch 43/100\n",
      "130/130 - 1s - loss: 0.6612\n",
      "Epoch 44/100\n",
      "130/130 - 1s - loss: 0.6569\n",
      "Epoch 45/100\n",
      "130/130 - 1s - loss: 0.6563\n",
      "Epoch 46/100\n",
      "130/130 - 1s - loss: 0.6523\n",
      "Epoch 47/100\n",
      "130/130 - 1s - loss: 0.6496\n",
      "Epoch 48/100\n",
      "130/130 - 1s - loss: 0.6465\n",
      "Epoch 49/100\n",
      "130/130 - 1s - loss: 0.6424\n",
      "Epoch 50/100\n",
      "130/130 - 1s - loss: 0.6420\n",
      "Epoch 51/100\n",
      "130/130 - 1s - loss: 0.6359\n",
      "Epoch 52/100\n",
      "130/130 - 1s - loss: 0.6340\n",
      "Epoch 53/100\n",
      "130/130 - 1s - loss: 0.6298\n",
      "Epoch 54/100\n",
      "130/130 - 1s - loss: 0.6253\n",
      "Epoch 55/100\n",
      "130/130 - 1s - loss: 0.6204\n",
      "Epoch 56/100\n",
      "130/130 - 1s - loss: 0.6181\n",
      "Epoch 57/100\n",
      "130/130 - 1s - loss: 0.6138\n",
      "Epoch 58/100\n",
      "130/130 - 1s - loss: 0.6084\n",
      "Epoch 59/100\n",
      "130/130 - 1s - loss: 0.6086\n",
      "Epoch 60/100\n",
      "130/130 - 1s - loss: 0.6005\n",
      "Epoch 61/100\n",
      "130/130 - 1s - loss: 0.5991\n",
      "Epoch 62/100\n",
      "130/130 - 1s - loss: 0.5937\n",
      "Epoch 63/100\n",
      "130/130 - 1s - loss: 0.5883\n",
      "Epoch 64/100\n",
      "130/130 - 1s - loss: 0.5860\n",
      "Epoch 65/100\n",
      "130/130 - 1s - loss: 0.5826\n",
      "Epoch 66/100\n",
      "130/130 - 1s - loss: 0.5744\n",
      "Epoch 67/100\n",
      "130/130 - 1s - loss: 0.5715\n",
      "Epoch 68/100\n",
      "130/130 - 1s - loss: 0.5663\n",
      "Epoch 69/100\n",
      "130/130 - 1s - loss: 0.5637\n",
      "Epoch 70/100\n",
      "130/130 - 1s - loss: 0.5569\n",
      "Epoch 71/100\n",
      "130/130 - 1s - loss: 0.5517\n",
      "Epoch 72/100\n",
      "130/130 - 1s - loss: 0.5493\n",
      "Epoch 73/100\n",
      "130/130 - 1s - loss: 0.5446\n",
      "Epoch 74/100\n",
      "130/130 - 1s - loss: 0.5403\n",
      "Epoch 75/100\n",
      "130/130 - 1s - loss: 0.5350\n",
      "Epoch 76/100\n",
      "130/130 - 1s - loss: 0.5304\n",
      "Epoch 77/100\n",
      "130/130 - 1s - loss: 0.5259\n",
      "Epoch 78/100\n",
      "130/130 - 1s - loss: 0.5212\n",
      "Epoch 79/100\n",
      "130/130 - 1s - loss: 0.5163\n",
      "Epoch 80/100\n",
      "130/130 - 1s - loss: 0.5144\n",
      "Epoch 81/100\n",
      "130/130 - 1s - loss: 0.5102\n",
      "Epoch 82/100\n",
      "130/130 - 1s - loss: 0.5058\n",
      "Epoch 83/100\n",
      "130/130 - 1s - loss: 0.5001\n",
      "Epoch 84/100\n",
      "130/130 - 1s - loss: 0.4986\n",
      "Epoch 85/100\n",
      "130/130 - 1s - loss: 0.4903\n",
      "Epoch 86/100\n",
      "130/130 - 1s - loss: 0.4866\n",
      "Epoch 87/100\n",
      "130/130 - 1s - loss: 0.4796\n",
      "Epoch 88/100\n",
      "130/130 - 1s - loss: 0.4747\n",
      "Epoch 89/100\n",
      "130/130 - 1s - loss: 0.4742\n",
      "Epoch 90/100\n",
      "130/130 - 1s - loss: 0.4673\n",
      "Epoch 91/100\n",
      "130/130 - 1s - loss: 0.4655\n",
      "Epoch 92/100\n",
      "130/130 - 1s - loss: 0.4588\n",
      "Epoch 93/100\n",
      "130/130 - 1s - loss: 0.4506\n",
      "Epoch 94/100\n",
      "130/130 - 1s - loss: 0.4483\n",
      "Epoch 95/100\n",
      "130/130 - 1s - loss: 0.4476\n",
      "Epoch 96/100\n",
      "130/130 - 1s - loss: 0.4416\n",
      "Epoch 97/100\n",
      "130/130 - 1s - loss: 0.4381\n",
      "Epoch 98/100\n",
      "130/130 - 1s - loss: 0.4314\n",
      "Epoch 99/100\n",
      "130/130 - 1s - loss: 0.4284\n",
      "Epoch 100/100\n",
      "130/130 - 1s - loss: 0.4227\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain_transformed, ytrain_transformed, epochs=100, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(xtest_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897892968168665"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ytest_transformed,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_inversed = scalerY.inverse_transform(preds)\n",
    "ys_inversed = scalerY.inverse_transform(ytest_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10278523384343731\n",
      "0.10771020784085339\n"
     ]
    }
   ],
   "source": [
    "ix = preds_inversed>0\n",
    "print(ys_inversed.reshape(-1,1)[ix].mean()*52)\n",
    "print(ys_inversed.reshape(-1,1)[~ix].mean()*52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13077360800011922\n",
      "0.15819831909229967\n"
     ]
    }
   ],
   "source": [
    "print(ys_inversed.reshape(-1,1)[ix].std()*np.sqrt(52))\n",
    "print(ys_inversed.reshape(-1,1)[~ix].std()*np.sqrt(52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## try stateful method ##########\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(4, batch_input_shape=(1,num_steps, 3),stateful=True))\n",
    "# model.add(Dense(3,activation='relu'))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (1, 4)                    128       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (1, 1)                    5         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2076/2076 - 8s - loss: 0.7299\n",
      "2076/2076 - 8s - loss: 0.7285\n",
      "2076/2076 - 8s - loss: 0.7281\n",
      "2076/2076 - 8s - loss: 0.7279\n",
      "2076/2076 - 8s - loss: 0.7278\n",
      "2076/2076 - 7s - loss: 0.7275\n",
      "2076/2076 - 7s - loss: 0.7272\n",
      "2076/2076 - 8s - loss: 0.7267\n",
      "2076/2076 - 8s - loss: 0.7262\n",
      "2076/2076 - 8s - loss: 0.7264\n",
      "2076/2076 - 8s - loss: 0.7264\n",
      "2076/2076 - 8s - loss: 0.7257\n",
      "2076/2076 - 8s - loss: 0.7254\n",
      "2076/2076 - 8s - loss: 0.7250\n",
      "2076/2076 - 7s - loss: 0.7252\n",
      "2076/2076 - 7s - loss: 0.7249\n",
      "2076/2076 - 7s - loss: 0.7245\n",
      "2076/2076 - 7s - loss: 0.7243\n",
      "2076/2076 - 7s - loss: 0.7239\n",
      "2076/2076 - 7s - loss: 0.7239\n",
      "2076/2076 - 7s - loss: 0.7235\n",
      "2076/2076 - 7s - loss: 0.7225\n",
      "2076/2076 - 7s - loss: 0.7221\n",
      "2076/2076 - 8s - loss: 0.7211\n",
      "2076/2076 - 8s - loss: 0.7226\n",
      "2076/2076 - 8s - loss: 0.7218\n",
      "2076/2076 - 8s - loss: 0.7216\n",
      "2076/2076 - 8s - loss: 0.7215\n",
      "2076/2076 - 8s - loss: 0.7196\n",
      "2076/2076 - 8s - loss: 0.7183\n",
      "2076/2076 - 8s - loss: 0.7193\n",
      "2076/2076 - 8s - loss: 0.7189\n",
      "2076/2076 - 8s - loss: 0.7173\n",
      "2076/2076 - 8s - loss: 0.7176\n",
      "2076/2076 - 8s - loss: 0.7177\n",
      "2076/2076 - 8s - loss: 0.7180\n",
      "2076/2076 - 9s - loss: 0.7153\n",
      "2076/2076 - 8s - loss: 0.7170\n",
      "2076/2076 - 8s - loss: 0.7165\n",
      "2076/2076 - 8s - loss: 0.7164\n",
      "2076/2076 - 8s - loss: 0.7157\n",
      "2076/2076 - 8s - loss: 0.7132\n",
      "2076/2076 - 8s - loss: 0.7151\n",
      "2076/2076 - 8s - loss: 0.7146\n",
      "2076/2076 - 8s - loss: 0.7139\n",
      "2076/2076 - 8s - loss: 0.7136\n",
      "2076/2076 - 8s - loss: 0.7136\n",
      "2076/2076 - 8s - loss: 0.7135\n",
      "2076/2076 - 8s - loss: 0.7107\n",
      "2076/2076 - 8s - loss: 0.7141\n",
      "2076/2076 - 8s - loss: 0.7119\n",
      "2076/2076 - 8s - loss: 0.7118\n",
      "2076/2076 - 8s - loss: 0.7114\n",
      "2076/2076 - 8s - loss: 0.7100\n",
      "2076/2076 - 8s - loss: 0.7106\n",
      "2076/2076 - 8s - loss: 0.7094\n",
      "2076/2076 - 8s - loss: 0.7092\n",
      "2076/2076 - 8s - loss: 0.7096\n",
      "2076/2076 - 8s - loss: 0.7086\n",
      "2076/2076 - 8s - loss: 0.7087\n",
      "2076/2076 - 8s - loss: 0.7069\n",
      "2076/2076 - 8s - loss: 0.7073\n",
      "2076/2076 - 8s - loss: 0.7064\n",
      "2076/2076 - 8s - loss: 0.7065\n",
      "2076/2076 - 8s - loss: 0.7065\n",
      "2076/2076 - 8s - loss: 0.7060\n",
      "2076/2076 - 8s - loss: 0.7042\n",
      "2076/2076 - 8s - loss: 0.7053\n",
      "2076/2076 - 8s - loss: 0.7050\n",
      "2076/2076 - 8s - loss: 0.7056\n",
      "2076/2076 - 8s - loss: 0.7038\n",
      "2076/2076 - 8s - loss: 0.7031\n",
      "2076/2076 - 8s - loss: 0.7037\n",
      "2076/2076 - 8s - loss: 0.7028\n",
      "2076/2076 - 8s - loss: 0.7026\n",
      "2076/2076 - 8s - loss: 0.7024\n",
      "2076/2076 - 8s - loss: 0.7032\n",
      "2076/2076 - 8s - loss: 0.7013\n",
      "2076/2076 - 8s - loss: 0.7028\n",
      "2076/2076 - 8s - loss: 0.7028\n",
      "2076/2076 - 8s - loss: 0.7020\n",
      "2076/2076 - 8s - loss: 0.7023\n",
      "2076/2076 - 8s - loss: 0.7014\n",
      "2076/2076 - 8s - loss: 0.7007\n",
      "2076/2076 - 8s - loss: 0.7020\n",
      "2076/2076 - 8s - loss: 0.6996\n",
      "2076/2076 - 8s - loss: 0.7007\n",
      "2076/2076 - 8s - loss: 0.7000\n",
      "2076/2076 - 8s - loss: 0.6998\n",
      "2076/2076 - 8s - loss: 0.7005\n",
      "2076/2076 - 8s - loss: 0.6998\n",
      "2076/2076 - 8s - loss: 0.7008\n",
      "2076/2076 - 8s - loss: 0.6991\n",
      "2076/2076 - 8s - loss: 0.7028\n",
      "2076/2076 - 8s - loss: 0.7008\n",
      "2076/2076 - 8s - loss: 0.7015\n",
      "2076/2076 - 8s - loss: 0.7012\n",
      "2076/2076 - 8s - loss: 0.7004\n",
      "2076/2076 - 8s - loss: 0.6999\n",
      "2076/2076 - 8s - loss: 0.7004\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    model2.fit(xtrain_transformed, ytrain_transformed, epochs=1, batch_size=1, shuffle=False, verbose=2)\n",
    "    model2.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model2.predict(xtest_transformed,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11771821231138269\n",
      "0.04320382910502953\n"
     ]
    }
   ],
   "source": [
    "preds_inversed2 = scalerY.inverse_transform(preds2)\n",
    "ix = preds_inversed2>0\n",
    "print(ys_inversed.reshape(-1,1)[ix].mean()*52)\n",
    "print(ys_inversed.reshape(-1,1)[~ix].mean()*52)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
